# -*- coding: utf-8 -*-
"""ShadrackProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11ZyROR22Qfg18X7ztDg4Lr_nNv3NvpQC

# Problem Statement:


Steel’s mechanical properties, such as tensile strength and hardness, are critical for selecting the right material in engineering applications. These properties depend on the chemical composition of the alloy, but testing them experimentally can be costly and time-consuming. The challenge is to develop a machine learning model that can accurately predict mechanical properties of steel based on its composition, enabling faster material evaluation and decision-making.

## Data Analysis and Exploration

The dataset contains information on the chemical composition of steels (e.g., Carbon, Manganese, Silicon, Chromium, Nickel, Molybdenum) and their corresponding mechanical properties (e.g., Tensile Strength, Yield Strength, Hardness, Elongation).

Data Loading and Inspection
"""

# Needed Libray Setup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix


from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from xgboost import XGBRegressor, XGBClassifier
from xgboost import plot_importance

# Load and read dataset
file = "/content/drive/MyDrive/Colab Notebooks/Steel- Property and Composition (Stainless Steel).csv"
try:
    df = pd.read_csv(file, encoding='latin-1')
except UnicodeDecodeError:
    # If 'latin-1' fails, try another common encoding like 'ISO-8859-1' or even 'cp1252'
    try:
        df = pd.read_csv(file, encoding='ISO-8859-1')
    except Exception as e:
        print(f"Could not decode the file with common encodings: {e}")
        # You might want to investigate the file encoding further here
        exit() # Exit if decoding fails

print(df.head())
print(df.info())
print(df.describe())

# Check for null values
df.isnull().sum()

# Percentage of missing values
missing_percentage = (df.isnull().sum() / len(df)) * 100
print(missing_percentage)

"""**With the above observation of missing values i will be performing the foloowing:**

Will Drop columns with >80–90% missing values:
They don’t carry enough information and will only add noise.
(e.g., C (Min), Mn (Min), Si (Min), Mo (Min), Ti (Min/Max), N, P (Min), S (Min)).

Keep and impute moderate missing columns (20–40%):
Use median imputation (robust against outliers).

Impute low missingness (<10%):
Use median imputation for numeric properties.
"""

# Step 1: Drop high-missing columns (>80%)
high_missing_cols = missing_percentage [missing_percentage  > 80].index
print("Dropping columns:", list(high_missing_cols))
df = df.drop(columns=high_missing_cols)

# Step 2: Separate numeric and categorical columns
numeric_cols = df.select_dtypes(include=np.number).columns
categorical_cols = df.select_dtypes(exclude=np.number).columns

# Step 3: Impute numeric columns with median
imputer_num = SimpleImputer(strategy="median")
df[numeric_cols] = imputer_num.fit_transform(df[numeric_cols])

# Step 4: Impute categorical columns (if any) with most frequent
if len(categorical_cols) > 0:
    imputer_cat = SimpleImputer(strategy="most_frequent")
    df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])

# Verify no missing values remain
print("Missing values after cleaning:\\n", df.isnull().sum().sum())

# Drop duplicates
df_cleaned= df.drop_duplicates()
df_cleaned

"""# Exploratory Data Analysis (EDA)"""

# Histograms for chemical composition and properties
numeric_cols = df.select_dtypes(include=np.number).columns
for col in numeric_cols:
    plt.figure(figsize=(6, 4))
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f"Distribution of {col}")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.show()

# Boxplots for outlier detection
for col in numeric_cols:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot of {col}")
    plt.show()

# Convert 'Reduction (%)' and 'S(Max)' to numeric, coercing errors to NaN
df['Reduction (%)'] = pd.to_numeric(df['Reduction (%)'], errors='coerce')
df['S(Max)'] = pd.to_numeric(df['S(Max)'], errors='coerce')

# Impute the newly created NaN values in 'Reduction (%)' and 'S(Max)' with the median
imputer_num = SimpleImputer(strategy="median")
df[['Reduction (%)', 'S(Max)']] = imputer_num.fit_transform(df[['Reduction (%)', 'S(Max)']])

# Correlation heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(numeric_only=True), annot=False, cmap="coolwarm", cbar=True)
plt.title("Correlation Heatmap of Steel Composition and Properties")
plt.show()

# Scatter plots between key features and tensile strength (example)
if "UTS (MPa)" in df.columns:
    for feature in [col for col in numeric_cols if col != "UTS (MPa)"]:
        plt.figure(figsize=(6, 4))
        sns.scatterplot(x=df[feature], y=df["UTS (MPa)"])
        plt.title(f"{feature} vs UTS (MPa)")
        plt.xlabel(feature)
        plt.ylabel("UTS (MPa)")
        plt.show()

"""## Build the Model

Feature Engineering
"""

#Feature Engineering
target = "UTS (MPa)" # The column containing tensile strength

# Drop property columns except target
drop_cols = ["UTS (Ksi)", "YS (MPa)", "YS (ksi)",
             "Elongation (%)", "Reduction (%)", "Hardness (HB)"]

X = df.drop(columns=[target] + drop_cols)
y = df[target]

# Handle categorical features using one-hot encoding
X = pd.get_dummies(X, columns=['SAE Grade', 'Conditions'], drop_first=True)

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
# Splitted the data into 80% training set and 20% test set
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""#  Modeling

Baseline
"""

# Linear Regression
lr_model = LinearRegression() # Instantiate the model
lr_model.fit(X_train, y_train) # Fit the model on the training set
lr_preds = lr_model.predict(X_test) # Predict on the test set

# Random Forest
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)
y_pred_rf = rf_reg.predict(X_test)

# XGBoost
xgb_reg = XGBRegressor(n_estimators=200, learning_rate=0.1, random_state=42)
xgb_reg.fit(X_train, y_train)
y_pred_xgb = xgb_reg.predict(X_test)

# Model Evaluation
print("Linear Regression RMSE:", mean_squared_error(y_test, lr_preds)**0.5)
print("Random Forest RMSE:", mean_squared_error(y_test, y_pred_rf)**0.5)
print("XGBoost RMSE:", mean_squared_error(y_test, y_pred_xgb)**0.5)

"""From the Above:

Linear Regression RMSE ≈ 2.0 → This looks suspiciously low. It could mean:

The target variable (y) has very small numeric values (so error looks small).

Or, more likely, there’s some data leakage (the model is “cheating” because features directly contain the target info).

Random Forest RMSE ≈ 58.4 and XGBoost RMSE ≈ 34.3 → These are much larger, which is more realistic for mechanical properties like tensile strength or hardness (usually in the 100s of MPa).
"""

# Lets Investigate
print(y.describe())

"""Since Linear Regression RMSE ≈ 2.0 → This looks suspiciously low which explains why the Linear Regression looked “too good”  the model was literally given the answers in other columns. For example, UTS (Ksi) is just a unit conversion of UTS (MPa), and YS (MPa) is strongly correlated with UTS (MPa).

To fix this, i have to remove all mechanical property columns except the target.

In the cell where i defined my features (X) and target (y),  i replaced it with the right drop to avoid leakage.

From my model evaluation Before:

Linear Regression RMSE ≈ 2.0 → way too good, because the model was “cheating” by using UTS/YS/Hardness columns (data leakage).

Now:

Linear Regression RMSE ≈ 244

Random Forest RMSE ≈ 214

XGBoost RMSE ≈ 205

Check R² score
RMSE alone doesn’t tell the full story. Will use R² to see how much variance is explained:
"""

print("Linear Regression R²:", r2_score(y_test, lr_preds))
print("Random Forest R²:", r2_score(y_test, y_pred_rf))
print("XGBoost R²:", r2_score(y_test, y_pred_xgb))

# The results are realistic: predicting mechanical properties from just composition
# and basic conditions is hard
# (since microstructure, heat treatment details, impurities, etc. also play big roles).

"""## Feature Importances"""

# Feature importance (Random Forest)
importances = rf_reg.feature_importances_
indices = np.argsort(importances)[::-1]

# Plot
plt.figure(figsize=(10, 6))
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), [X.columns[i] for i in indices], rotation=90)
plt.title("Feature Importance (Random Forest)")
plt.show()

from xgboost import plot_importance

# Plot XGBoost feature importance
plt.figure(figsize=(10, 6))
plot_importance(xgb_reg, importance_type="weight", xlabel="F-score")
plt.title("Feature Importance (XGBoost)")
plt.show()

"""**Interpretation**

---



XGBoost is the best of the three: it has the lowest test RMSE (~205 MPa) and the highest R² (~0.50), so it explains about half the variance in UTS with the current features and preprocessing.

Random Forest performs second best. Linear regression is weakest, which fits the expectation that the relationship is nonlinear.

Tuned with RandomizedSearchCV.


---



This will show me the “best” model before i finalize the conclusion.
"""

# Base XGBoost model
xgb_model = XGBRegressor(random_state=42, n_jobs=-1)

# Define hyperparameter search space
param_dist = {
    "n_estimators": [100, 200, 500, 1000],
    "learning_rate": [0.01, 0.05, 0.1, 0.2],
    "max_depth": [3, 5, 7, 10],
    "subsample": [0.6, 0.8, 1.0],
    "colsample_bytree": [0.6, 0.8, 1.0],
    "min_child_weight": [1, 3, 5]
}

# Randomized search with cross-validation
random_search = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=param_dist,
    n_iter=20,          # number of random combos
    cv=3,               # 3-fold cross-validation
    scoring="r2",       # optimize for R²
    verbose=2,
    random_state=42,
    n_jobs=-1
)

# Fit search
random_search.fit(X_train, y_train)

# Get best model
best_xgb = random_search.best_estimator_
print("Best Parameters:", random_search.best_params_)

# Evaluate on test set
y_pred_best = best_xgb.predict(X_test)
rmse = mean_squared_error(y_test, y_pred_best)**0.5
r2 = r2_score(y_test, y_pred_best)

print(f"Tuned XGBoost RMSE: {rmse:.4f}")
print(f"Tuned XGBoost R²: {r2:.4f}")

"""# Project Conclusion


Best Model & Performance

After comparing Linear Regression, Random Forest, and XGBoost, the tuned XGBoost model with parameters:achieved the best overall performance:

RMSE ≈ 236 MPa

R² ≈ 0.34

This means the model explains about 34% of the variance in tensile strength (UTS) based on alloy composition. While not perfect, this shows meaningful predictive ability given the complexity of steel behavior.

Dump and load the model for deployment
"""

import joblib

# Save the trained model
joblib.dump(best_xgb, "steel_strength_xgb_model.pkl")

# Load the model
loaded_model = joblib.load("steel_strength_xgb_model.pkl")